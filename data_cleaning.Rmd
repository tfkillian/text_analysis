---
title: "Data Cleaning"
author: "Theo Killian"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
vignette: >
  %\VignetteEngine{knitr::knitr}
  %\VignetteIndexEntry{depmap}
  %\usepackage[utf8]{inputenc}
---

```{r setup, include=FALSE}
suppressPackageStartupMessages(library("dplyr"))
knitr::opts_chunk$set(collapse=TRUE, comment="#>", warning=FALSE, message=FALSE)
```

# Introduction

This report performs a textual analysis of the infamous [Bush v. Gore 2000](https://www.law.cornell.edu/supct/html/00-949.ZPC.html)
opinion. This opinion was written by an anonymous US Supreme Court Justice,
likely by one of the 5 conservative Supreme Court justices serving on the court
at that time: O'Connor, Rehnquist, Thomas, Kennedy and Scalia. In this analysis,
we utilize a number of NLP techniques, such as hierarchical clustering,
bootstrap consensus trees, characteristic vocabulary, and other methods. We have
sampled the opinions written by each of the five conservative justices between
the period 1999-2001 for comparison to the [Bush v. Gore 2000](https://www.law.cornell.edu/supct/html/00-949.ZPC.html)
opinion, in order to ascertain the probable author of this document.

```{r load_libraries}
library("readtext")
library("quanteda")
library("dplyr")
set.seed(123)
```

### Load Data

The Bush v. Gore opinion is read into R as a single `readtext` object.  We will
also compile the opinions written by each of the five conservative justices
between the period 1999-2001 (+/- 1 year from when the anonymous SC opinion was
written in 2000). Each body of documents from each justice can be read a single
`readtext` 'glob' where each single document can be individually selected or
evaluated together a single object.

```{r load_data}
opinion <- readtext("./opinions/Bush_v_Gore.txt")

KENNEDY <- system.file("./opinions/Kennedy/", package = "readtext")
kennedy <- readtext(paste0(KENNEDY, "./opinions/Kennedy/*"))

OCONNOR <- system.file("./opinions/OConnor/", package = "readtext")
oconnor <- readtext(paste0(OCONNOR, "./opinions/OConnor/*"))

REHNQUIST <- system.file("./opinions/Rehnquist/", package = "readtext")
rehnquist <- readtext(paste0(REHNQUIST, "./opinions/Rehnquist/*"))

SCALIA <- system.file("./opinions/Scalia/", package = "readtext")
scalia <- readtext(paste0(SCALIA, "./opinions/Scalia/*"))

THOMAS <- system.file("./opinions/Thomas/", package = "readtext")
thomas <- readtext(paste0(THOMAS, "./opinions/Thomas/*"))
```

```{r}
kennedy
```

```{r}
oconnor
```

```{r}
rehnquist
```

```{r}
scalia
```

```{r}
thomas
```

### Corpus Generation

[Corpuses](https://tutorials.quanteda.io/basic-operations/corpus/corpus/) for
each SC justice are generated using the `quanteda` R package. A corpus is a data
frame consisting of a character vector for each documents. The summary of each
corpus lists the statistics on `Types,` `Tokens` and `Sentences` for each
document.

```{r corpuses}
opinion_corpus <- corpus(opinion)
kennedy_corpus <- corpus(kennedy)
oconnor_corpus <- corpus(oconnor)
rehnquist_corpus <- corpus(rehnquist)
scalia_corpus <- corpus(scalia)
thomas_corpus <- corpus(thomas)
```

### Data Cleaning

We will need to convert the text to lower case and remove any non-ASCII
characters so that the texts can be compared for later analysis. The corpuses
will be tokenized, English stop words (such as "the", "and" etc.) removed and
the corpuses converted to document feature matrices (DFMs).

```{r}
## convert the corpus to all lower case
opinion_lower <- tolower(opinion_corpus)
kennedy_lower <- tolower(kennedy_corpus)
oconnor_lower <- tolower(oconnor_corpus)
rehnquist_lower <- tolower(rehnquist_corpus)
scalia_lower <- tolower(scalia_corpus)
thomas_lower <- tolower(thomas_corpus)

## convert the coprpus into tokens
opinion_tokes <- tokens(opinion_lower)
kennedy_tokes <- tokens(kennedy_lower)
oconnor_tokes <- tokens(oconnor_lower)
rehnquist_tokes <- tokens(rehnquist_lower)
scalia_tokes <- tokens(scalia_lower)
thomas_tokes <- tokens(thomas_lower)

## remove stop words from corpus
opinion_nostop <- tokens_select(opinion_tokes, pattern = stopwords('en'),
                                selection = 'remove')
kennedy_nostop <- tokens_select(kennedy_tokes, pattern = stopwords('en'),
                                selection = 'remove')
oconnor_nostop <- tokens_select(oconnor_tokes, pattern = stopwords('en'),
                                selection = 'remove')
rehnquist_nostop <- tokens_select(rehnquist_tokes, pattern = stopwords('en'),
                                selection = 'remove')
scalia_nostop <- tokens_select(scalia_tokes, pattern = stopwords('en'),
                                selection = 'remove')
thomas_nostop <- tokens_select(thomas_tokes, pattern = stopwords('en'),
                                selection = 'remove')

## remove numbers and punctuation from corpus
opinion_cleaned <- tokens_remove(tokens(opinion_nostop, remove_punct = TRUE,
                                 remove_numbers = TRUE), stopwords("english"))
kennedy_cleaned <- tokens_remove(tokens(kennedy_nostop, remove_punct = TRUE,
                                 remove_numbers = TRUE), stopwords("english"))
oconnor_cleaned <- tokens_remove(tokens(oconnor_nostop, remove_punct = TRUE,
                                 remove_numbers = TRUE), stopwords("english"))
rehnquist_cleaned <- tokens_remove(tokens(rehnquist_nostop, remove_punct = TRUE,
                                   remove_numbers = TRUE), stopwords("english"))
scalia_cleaned <- tokens_remove(tokens(scalia_nostop, remove_punct = TRUE,
                                 remove_numbers = TRUE), stopwords("english"))
thomas_cleaned <- tokens_remove(tokens(thomas_nostop, remove_punct = TRUE,
                                remove_numbers = TRUE), stopwords("english"))

# to remove extra words/tokens, we can remove on "pattern"
# pattern = c('immig*', 'migra*')

## Create the corpus dfm
opinion_dfm <- dfm(opinion_cleaned)
kennedy_dfm <- dfm(kennedy_cleaned)
oconnor_dfm <- dfm(oconnor_cleaned)
rehnquist_dfm <- dfm(rehnquist_cleaned)
scalia_dfm <- dfm(scalia_cleaned)
thomas_dfm <- dfm(thomas_cleaned)
```

Save the cleaned document feature matrices as *.rds* files in `opinions` folder.

```{r}
saveRDS(opinion_dfm, file = "./opinions/dfms/opinion_dfm.rds")
saveRDS(kennedy_dfm, file = "./opinions/dfms/kennedy_dfm.rds")
saveRDS(oconnor_dfm, file = "./opinions/dfms/oconnor_dfm.rds")
saveRDS(rehnquist_dfm, file = "./opinions/dfms/rehnquist_dfm.rds")
saveRDS(scalia_dfm, file = "./opinions/dfms/scalia_dfm.rds")
saveRDS(thomas_dfm, file = "./opinions/dfms/thomas_dfm.rds")
```

*Session Info*

```{r sessionInfo}
sessionInfo()
```